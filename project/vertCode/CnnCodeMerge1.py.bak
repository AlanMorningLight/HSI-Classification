#from __future__ import print_function
# -*- coding: utf-8 -*-
"""
Created on Thu Nov 17 10:14:25 2016
@author: Administrator
去掉relu激活函数，第三个位置识别， 35次迭代acc: 0.9018 - val_loss: 0.6912 - val_acc: 0.8025
"""
'''
用一个Graph模型训练验证码图片的四个位置；
图像处理:将验证码图片转化成灰度图像，图像背景是黑色
'''


import numpy as np
np.random.seed(1337)  # for reproducibility

from keras.models import Model,Graph
from keras.layers import Dense, Dropout, Activation, Flatten,merge
from keras.layers import Convolution2D, MaxPooling2D
from keras.utils import np_utils
import numpy as np
from keras.callbacks import EarlyStopping
from ImagePre import *

#%%
outBasePath="D:/project/VertCode/mycode/output/model/"
picBasePath="D:/project/VertCode/tuniu"
labPath="D:/project/VertCode/1(1).txt"
X_train,Y_train=getPicArrWithLab(picBasePath,labPath)

#%%
# input image dimensions
img_rows, img_cols = 30, 80
# number of convolutional filters to use
nb_filters = 40
# size of pooling area for max pooling
pool_size = (2, 2)
# convolution kernel size
kernel_size = (3, 3)
#
input_shape=(1,30,80)
#
nb_classes=36
#
batch_size=128
#
nb_epoch=1000

"""
shared_node 尝试
"""
def getCNNGraphShare():
    model=Graph()
    model.add_input(name="input",input_shape=input_shape)
    model.add_shared_node(Convolution2D(32, kernel_size[0], kernel_size[1],
                            border_mode='valid',
                            input_shape=input_shape,dim_ordering="th"),name="shared_conv1",
                            inputs=["input","input","input","input"],
                            outputs=["shared_conv1_output1","shared_conv1_output2","shared_conv1_output3","shared_conv1_output4"])
    #model.add_node(Activation('relu'),name="act1",input="conv1")
    
    model.add_shared_node(Convolution2D(32, kernel_size[0], kernel_size[1],
                        border_mode='valid',
                        input_shape=input_shape,dim_ordering="th"),name="shared_conv2",inputs=
                        ["shared_conv1_output1","shared_conv1_output2","shared_conv1_output3","shared_conv1_output4"],
                        outputs=["shared_conv2_output1","shared_conv2_output2","shared_conv2_output3","shared_conv2_output4"])
    #model.add_node(Activation('relu'),name="act1",input="conv1")
    
    model.add_shared_node(MaxPooling2D(pool_size=pool_size),name="pool1",
                          inputs=["shared_conv2_output1","shared_conv2_output2","shared_conv2_output3","shared_conv2_output4"],
                          outputs=["shared_pool1_output1","shared_pool1_output2","shared_pool1_output3","shared_pool1_output4"])
    model.add_shared_node(Dropout(0.25),name="drop1",
                   inputs=["shared_pool1_output1","shared_pool1_output2","shared_pool1_output3","shared_pool1_output4"],
                   outputs=["shared_drop1_output1","shared_drop1_output2","shared_drop1_output3","shared_drop1_output4"])
    
    model.add_shared_node(Flatten(),name="Flatten",
                          inputs=["shared_pool1_output1","shared_pool1_output2","shared_pool1_output3","shared_pool1_output4"],
                          outputs=["shared_Flatten_output1","shared_Flatten_output2","shared_Flatten_output3","shared_Flatten_output4"])
    model.add_node(Dense(128),name="dense1",input="Flatten")
    #    model.add(Activation('relu'))
    model.add_node(Dropout(0.5),name="drop2",input="dense1")
    model.add_node(Dense(nb_classes),name="dense2",input="dense1")
    model.add_node(Activation('softmax'),name="soft1",input="dense2")
    
    model.add_output(name="output1",input="soft1")
    model.add_output(name="output2",input="soft1")
    model.add_output(name="output3",input="soft1")
    model.add_output(name="output4",input="soft1")
    
    model.compile(loss='categorical_crossentropy',
                  optimizer='adadelta',
                  metrics=['accuracy'])
    return model
#CNNGraphShareModel=getCNNGraphShare()
#
#early_stopping = EarlyStopping(monitor='val_loss', patience=2)
#CNNGraphShareModel.fit({'input':X_train,'output1':Y_train[:,0,:],'output2':Y_train[:,1,:],
#          'output3':Y_train[:,2,:],'output4':Y_train[:,3,:]},
#          batch_size=batch_size, nb_epoch=nb_epoch,verbose=1, 
#          validation_split=0.2,shuffle=True)
#%%         


"""
三步：权重共享结构+对每个位置分别训练一个Dense+四个output
merge_mode:sum，100次迭代准确率37%
merge_mode:concat，100次迭代准确率60~70%
"""
def getCNNGraphConcat():
    model=Graph()
    model.add_input(name="input",input_shape=input_shape)
    model.add_node(Convolution2D(32, kernel_size[0], kernel_size[1],
                                border_mode='valid',
                                input_shape=input_shape,dim_ordering="th"),name="conv1",
                                input="input")
    model.add_node(Activation('relu'),name="act1",input="conv1")
    
    model.add_node(Convolution2D(32, kernel_size[0], kernel_size[1])
                               ,name="conv2",input="act1")
    model.add_node(Activation('relu'),name="act2",input="conv2")
    
    model.add_node(MaxPooling2D(pool_size=pool_size),name="pool1",input="act2")
    model.add_node(Dropout(0.25),name="drop1",input="pool1")
    
    
    #第一个位置
    model.add_node(Convolution2D(32,kernel_size[0],kernel_size[1],activation="relu"
                                 ),name="p1_input",input="drop1")
    model.add_node(Flatten(),name="p1_flatten",input="p1_input")
    model.add_node(Dense(128,activation="relu"),name="p1_dense1",input="p1_flatten")
    model.add_node(Dropout(0.5),name="p1_drop",input="p1_dense1")
    model.add_node(Dense(nb_classes,activation="softmax"),name="p1_dense2",input="p1_drop")
    #第二个位置
    model.add_node(Convolution2D(32,kernel_size[0],kernel_size[1],activation="relu"
                                 ),name="p2_input",input="drop1")
    model.add_node(Flatten(),name="p2_flatten",input="p2_input")
    model.add_node(Dense(128,activation="relu"),name="p2_dense1",input="p2_flatten")
    model.add_node(Dropout(0.5),name="p2_drop",input="p2_dense1")
    model.add_node(Dense(nb_classes,activation="softmax"),name="p2_dense2",input="p2_drop")
    #第一个位置
    model.add_node(Convolution2D(32,kernel_size[0],kernel_size[1],activation="relu"
                                 ),name="p3_input",input="drop1")
    model.add_node(Flatten(),name="p3_flatten",input="p3_input")
    model.add_node(Dense(128,activation="relu"),name="p3_dense1",input="p3_flatten")
    model.add_node(Dropout(0.5),name="p3_drop",input="p3_dense1")
    model.add_node(Dense(nb_classes,activation="softmax"),name="p3_dense2",input="p3_drop")
    #第一个位置
    model.add_node(Convolution2D(32,kernel_size[0],kernel_size[1],activation="relu"
                                 ),name="p4_input",input="drop1")
    model.add_node(Flatten(),name="p4_flatten",input="p4_input")
    model.add_node(Dense(128,activation="relu"),name="p4_dense1",input="p4_flatten")
    model.add_node(Dropout(0.5),name="p4_drop",input="p4_dense1")
    model.add_node(Dense(nb_classes,activation="softmax"),name="p4_dense2",input="p4_drop")
    
    #输出
    model.add_output(name="output",inputs=["p1_dense2","p2_dense2","p3_dense2","p4_dense2"],merge_mode="concat")
    
    model.compile(loss='categorical_crossentropy',
                  optimizer='adadelta',
                  metrics=['accuracy'])
    return model

#early_stopping = EarlyStopping(monitor='val_loss', patience=2)
Y_train_graph=np.concatenate((Y_train[:,0,:],Y_train[:,1,:],Y_train[:,2,:],Y_train[:,3,:]),axis=1)
CNNGraphConcatModel=getCNNGraphConcat()
CNNGraphConcatModel.fit({'input':X_train,'output':Y_train_graph},
          batch_size=batch_size, nb_epoch=nb_epoch,verbose=1, 
          validation_split=0.2,shuffle=True)
          
json_string=CNNGraphConcatModel.to_json()
open(outBasePath+'modelmerge'+'.json','w').write(json_string)
CNNGraphConcatModel.save_weights(outBasePath+"modelmerge"+"_weight.h5")
